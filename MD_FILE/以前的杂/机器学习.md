## 机器学习

https://www.bilibili.com/video/BV1jK4y1D7hE?p=17&spm_id_from=pageDriver 学到17

### 模型选择

1.如果数据中包含特征和标签，希望学习特征和标签之间的对应关系，那么应该采用**监督学习**

2.如果没有标签，希望探索特征自身的规律，那么可以采用**非监督学习**

3.如果学习任务由一些系列行动和对应的奖赏组成，那么可以采用**强化学习**

4.如果需要预测的标签是分类变量，比如预测股票上涨还是下跌，应该采用**分类方法**

5.如果标签是连续的数值变 量，比如预测股票具体涨多少，那么可以采用**回归方法**

---

### 特征值化  ONE-HOT编码

```python
# pandas 里面有个方法 可以生成ONE-HOT编码
pd.get_dummies(df['col1'])

```

---

### 特征工程预处理

```txt
当各个数据相差很大的时候，需要对数据进行预处理，归一化 取值在一定范围内，标准化。
```

#### 数据归一化

```python
#当各个数据相差很大的时候，需要对数据进行归一化操作
from sklearn.preprocessing import MinMaxScaler
mm=MinMaxScaler()
归一化结果=mm.fit_transform(需要归一化的DF)

```

#### 数据标准化

```
# 有可能是错的，照着归一化写的
from sklearn.preprocessing import StandardScaler
mm=StandardScalerr()
归一化结果=mm.StandardScaler(需要归一化的DF)

```

---

### KNN+交叉验证

```python
import sklearn.datasets as datasets # 数据
from sklearn.neighbors import KNeighborsClassifier  # 算法
from sklearn.model_selection import train_test_split  #分离数据的工具

iris=datasets.load_iris()
feature=iris['data'] #样本数据
target=iris['target'] #样本结果
x_train,x_test,y_tarin,y_test=train_test_split(feature,target,test_size=0.2,random_state=2020) #拆分数据  test_size 是训练集占用的
# 训练集        测试集       训练结果           测试结果
x_train.shape,x_test.shape,y_tarin.shape,y_test.shape #拆分数据后的维度
((120, 4), (30, 4), (120,), (30,))

#实例化模型对象  
knn=KNeighborsClassifier(n_neighbors=3)  # n_neighbors模型的超参数,超参数大小不同回导致结果不同
										# 寻找最优n_neighbors 可以用遍历的办法
knn1=knn.fit(x_train,y_tarin)   # 训练数据 训练集 和结果集 训练集 必须得是2维度得
knn1                             #已经训练好得模型

y_text=knn1.predict(x_test) # 放入测试集  knn1.predict([[value1,value2]]) 也可以传入单个的数据																		预测单个结果


y_true=y_test
print('模型得分类结果：',y_text)
print('真实的分类结果: ',y_true)

knn.score(x_test,y_test) #给模型评分

```

#### 测试级和训练集都归一化

```python
from sklearn.preprocessing import MinMaxScaler
mm=MinMaxScaler()
归一化后的训练集 =mm.fit_transform(需要归一化的训练集(大的)) 
归一化后的测试集 =mm.transform(需要归一化的测试集(小的))  #不用加fit

```

#### 交叉验证

**可以验证多个模型，选择最优模型**

```python
from sklearn.model_selection import cross_val_score # 交叉验证
# cross_val_score(estimato='训练模型',X='训练集数据',y='训练集数据',cv='折数需要拆分几次')
import sklearn.datasets as datasets  # 得到数据
from sklearn.model_selection import train_test_split # 拆分数据集
from sklearn.neighbors import KNeighborsClassifier  # KNN模型
iris=datasets.load_iris()
feature=iris['data']
target=iris['target']
x_tarin,x_test,y_train,y_test=train_test_split(feature,target,test_size=0.2,random_state=2020)
mydict={}
for i in range(3,20):
    for y in range(3,20):
        knn=KNeighborsClassifier(n_neighbors=i) # 实例化模型
        score=cross_val_score(knn,x_tarin,y_train,cv=5).mean() # 交叉模型的均值 准确率
        # keys_str=s_str=str(i)+'_'+str(y)
        mydict[i]=score 
import numpy as np
values_max=np.array(list(mydict.values())).max()
for x,y in mydict.items():
    if y == values_max:
        print(f'values_max:{values_max}')
        print(x)
```

#### K-FOLD拆分数据

```python
import numpy as np
from sklearn.model_selection import KFold #拆分工具
data=np.array([1,2,3,4,5,6,7,8,9,10])
kfold=KFold(n_splits=3,shuffle=True,random_state=2)
# n_split 就是折数 shuffle是否对数据洗牌,random_state为随机种子 固定随机性
for train,text in kfold.split(data):
    print('train',train,'text',text)
-------------------------------------------------------------
结果：
train [2 3 6 7 8 9] text [0 1 4 5]
train [0 1 4 5 6 8 9] text [2 3 7]
train [0 1 2 3 4 5 7] text [6 8 9]
-------------------------------------------------------------

# 拆分后使用
from sklearn.model_selection import cross_val_score
iris=datasets.load_iris()
x,y =iris.data,iris.target
knn=KNeighborsClassifier(n_neighbors=5)

n_folds=5
kf=KFold(n_folds,shuffle=True,random_state=42).get_n_splits(x)
score=cross_val_score(knn,x,y,cv=kf)
score.mean()
  
```

---

### 线性回归 +回归算法的评价指标

单因子线形回归

```html

根据数据，确定两种或两种以上变量间相互依赖的定量关系
y=f(X1,X2....Xn)
一元回归：y=f(x)
多元回归：y=f(X1,X2....Xn)
线性回归：y=ax + b
非线性回归： y=ax2+bx+c
房价=f(面积)

比如 y=ax+b 要求出a,b 的值最合理的状态是
当 a,b是各种状态的时候
（预测结果yi - 实际y的结果）**2 /样本的数量*2  是最小（minimize）的时候 a,b的值是最合理的(让损失函数是最小的)

梯度下降法可以寻找 a,b的值 让损失函数最小

使用回归方法判断房价的合理步骤
1 使用历史数据生成损失函数
2 使用梯度下降或者其他方法求解最小花损失函数的模型参数

```

```html

import pandas as pd
hello=[i for i in range(1,20)]
kitty=[i*5+ 2 for i in hello]
data=pd.DataFrame(data=[hello,kitty])
data=data.T

data.columns=['x','y']

# 建立模型
import numpy as np
from sklearn.linear_model import LinearRegression  #线形回归
x=np.array(data.x).reshape(-1,1)
y=np.array(data.y).reshape(-1,1)
lr_mode=LinearRegression()   #实力话模型
lr_mode.fit(x,y) #训练模型，报错的时候，要把SERIES结构的数据转换成array数组，而且结构要改成2维的

y_predict=lr_mode.predict([[3]]) #测试训练集

a=lr_mode.coef_  # 查看a的结果  
b=lr_mode.intercept_ #查看b的结果

# y=ax+b

#模型评分
from sklearn.metrics import mean_absolute_error,r2_score
#MSE接近0更好
#R2 接近1 更好
MSN=mean_absolute_error(y,y_predict)
R2=r2_score(y,y_predict)
print(MSN) 
print(R2)

```

连续性的数据，用线性回归

---
